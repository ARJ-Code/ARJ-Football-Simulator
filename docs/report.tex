\documentclass{article}
\usepackage{graphicx} 
\usepackage[text={18cm,21cm},centering]{geometry}

\title{Proyecto final de IA y Simulación}
\author{Juan Carlos Espinosa Delgado C-411 \\
        Raudel Gómez Molina C-411\\
        Alex Sierra Alcalá C-411
}
\date{28 de arbil de 2024}
\begin{document}

\maketitle
\newpage

\tableofcontents
\newpage

\section{Introducción}
El fútbol es un deporte de equipo muy popular en todo el mundo, y su simulación mediante técnicas de inteligencia
artificial (IA) se ha convertido en un área de investigación activa. La simulación de partidos de fútbol permite a
los investigadores y profesionales del deporte estudiar diferentes estrategias, tácticas y escenarios de juego sin la
necesidad de partidos físicos reales.

Este informe presenta los resultados de un proyecto de simulación de un partido de fútbol utilizando técnicas de IA. 
El objetivo del proyecto era desarrollar un modelo de simulación que pudiera generar partidos de fútbol realistas y 
que permitiera a los usuarios experimentar con diferentes parámetros y estrategias para hacer predicciones de estos 
partidos.
\newpage
\section{Modelación basada en Agentes}
Para realizar simulaciones de los juegos hacemos uso de agentes inteligentes, nuestro
ambiente consistirá en el estado actual del juego, que está compuesto por sus jugadores, la
estrategia que siguen, sus atributos de jugador actuales, los entrenadores, el terreno y las 
estadísticas actuales del partido.Nuestros agentes serán los jugadores y entrenadores y su función 
objetivo será ganar el partido.

\subsection{Modelación del ambiente}
Nuestro ambiente consta de las siguientes características:

\begin{enumerate}
      \item \textbf{Accesibilidad}: Nuestro ambiente es totalmente accesible, cada jugador posee conocimiento acerca del
            resto de los jugadores y de sus posiciones en el terreno, de dónde se encuentra el balón y de las estadísticas 
            actuales del partido. Importante aclarar que para los jugadores se tiene en cuenta un atributo de visión y 
            cansancio, que limita las acciones que este puede tomar.
            
      \item \textbf{Determinista o no determinista}: Nuestro ambiente es un ambiente no determinista, ya que, al no
            conocer el resultado de cada acción con certeza, existe incertidumbre acerca del estado del ambiente luego de 
            realizar una acción.
            
      \item \textbf{Episódico o secuencial}: Este ambiente es secuencial, ya que las decisiones del agente pueden
            influir de forma positiva o negativa en el futuro, por lo que tiene que razonar las consecuencias de sus acciones.
            
      \item \textbf{Estático o dinámico}: Es un ambiente estático, ya que permanece inalterable mientras no se
            realice una acción sobre él, de hecho, todos los jugadores deben realizar su acción (la cual puede ser no hacer 
            nada) para poder avanzar en el partido.
            
      \item \textbf{Discreto o continuo}: Optamos por que el tiempo fuera discreto, aunque eso no aleje un poco de la
            realidad. En cada instancia de tiempo, cada jugador puede realizar un número constante de acciones (solo una). 
            Cada jugador no puede decidir de forma independiente el instante exacto de tiempo en que realizará su acción, 
            sino que se sigue un orden preestablecido en cada instancia de tiempo. Todas estas consideraciones simplifican 
            de forma considerable el problema aunque lo alejan un poco de la realidad.
            
\end{enumerate}

\subsection{Tipos de Agentes}
\subsubsection{Agente jugador}
Nuestros jugadores son agentes puramente reactivos ya que basan su decision enteramente en el presente, sin referencia 
a lo que haya pasado anteriormente. Estos simplemente responden directamente al ambiente. Implementamos varias 
estrategias que pueden ser usadas por el agente estas perfectamente pueden ser combinadas en un mismo juego por 
varios agentes y actúan de forma independiente.

Una de estas estrategias se basa en tipos de comportamiento entre los que se encuentran: ofensivo, defensivo, evitar 
cansancio y el respeto por la posición inicial impuesta por el entrenador. En dependencia de si los jugadores son 
defensas, mediocampistas o delanteros, tendrán una estrategia basada en una heurística, la cual funciona dándole 
pesos a cada uno de los comportamientos del agente, y un pequeño peso a un comportamiento aleatorio. De esta forma 
cada jugador puede variar su configuración de comportamiento en dependencia de su posición en la alineación.

Otra estrategia implementada se basa en la búsqueda del posible árbol de juego (esta implementación tuvo sus complicaciones 
ya que las transiciones de posibles acciones son no deterministas). Por esta razón 
optamos por evaluar todas las posibles acciones del agente y tomando cada una de estas simular el comportamiento del 
resto de los agentes y en la próxima instancia de tiempo volver a evaluar todas las posibles acciones del agente y así 
hasta cierto nivel que se especifica. Una vez finalizadas estas simulaciones se evalúa que tan bueno es la posición 
obtenida en el campo usando una función de evaluación y se toma la mejor decisión en base a este número. En esta 
función se le da una valoración a qué tan bien está posicionado el equipo del jugador ofensivamente en caso de tener 
el balón o defensivamente en caso de que la posesión sea del equipo contrario. Para hacer esta valoración tenemos en 
cuenta la posición del balón y la distancia a la que este se encuentra de la portería rival, las oportunidades de 
pase, el marcador actual del partido y se hace una valoración también de la ventaja que tiene un equipo sobre otro 
en el terreno haciendo uso de las estadísticas del partido con diferentes pesos en donde por ejemplo se usan los 
goles, faltas, pases, pases, tiros y tarjetas, donde un gol tiene bastante mas peso que un pase  o un disparo. 
Teniendo en cuenta los valores numéricos todos estos factores el jugador evalúa la posición ofensiva/defensiva de 
su equipo basado en reglas de lógica difusa donde por ejemplo, si el jugador considera que un atacante está ¨lejos¨ 
(según lo que considere lejos ese jugador) de la portería rival, este no tiene una posición ofensiva buena.
Todas las reglas mencionadas anteriormente se aplican al algoritmo de evaluación usando lógica difusa.


Como en la vida real, un jugador no sabe cómo percibe el resto de los jugadores los datos de un partido, este no 
tiene conocimiento de sus funciones de evaluación en nuestra simulación, por lo que a la hora de ejecutar la búsqueda
su predicción del partido no es del todo exacta, haciendo su pensamiento más realista. Para intuir las acciones del 
resto de los jugadores, hace uso de las heurísticas explicadas anteriormente, dependiendo si el jugador a predecir 
es defensor, centrocampista o delantero, teniendo en cuenta los comportamientos màs probables de estos tipos de 
jugadores.

\subsubsection{Agente entrenador}
Nuestros agentes entrenadores, son agentes puramente reactivos ya que, al igual que los jugadores, basan 
su decisión enteramente en el presente, sin referencia a lo que haya pasado anteriormente.

Su primera tarea será la de elegir el 11 inicial. Para ello tienen distintas posibilidades de formaciones 
(4-3-3, 5-3-2, etc). Para cada formación eligen a los 11 jugadores haciendo uso de una heurística que consiste en 
que el mejor 11 posible a alinear es aquel que mejores jugadores tenga en general (basado en los atributos de los 
jugadores de nuestro dataset). Optamos por este heurística de evaluación un tanto greedy ya que evaluar todas las 
combinaciones sobre el campo de los jugadores es un problema combinatorio muy costoso computacionalmente, esto tiene la
desventaja que solo se evalúa el jugador que mejor para una posición y no existe una evaluación conjunta. El manager 
explora todas las combinaciones de 11 jugadores posibles de la plantilla en donde ningún jugador esté fuera de 
posición (por ejemplo no ve ninguna combinación en la que Messi sea portero) todo esto después de aplicar la 
heurística descrita anteriormente. Luego de elegir para cada formación su mejor alineación, el entrenador simula 
varias veces todas sus formaciones posibles y las del entrenador rival y decide alinear la que màs porcentaje de 
victoria le dé. Al ser no determinista nuestra simulación y no saber el resultado de cada acción en el juego con 
certeza, no pudimos hacer usos de algoritmos como el \textbf{MTCS} para el cual está probada su eficacia en este tipo de 
contextos pero en el caso de los deterministas, por lo que se optó por la idea descrita anteriormente.

Una vez empezado el partido con las alineaciones decididas por cada entrenador, estos también pueden ejecutar 
acciones. Entre estas se encuentran hacer cambios de jugadores y cambios de formaciones. En los cambios de 
formaciones los entrenadores si podrán situar jugadores en posiciones que no aparezcan entre las posibles a jugar 
por estos, teniendo una penalización en sus atributos de habilidades (ya que en la vida real los jugadores que juegan 
fuera de sus posiciones habituales no son igual de buenos que en estas). Para tomar las decisiones sobre qué acción 
ejecutar, los entrenadores siguen el mismo algoritmo descrito para elegir la alineación inicial pero en este caso 
asumen que el técnico rival jugará random ya que no es posible probar todas las posibles acciones y llegar hasta el 
final del partido.

Otra estrategia implementada para los entrenadores es siguiendo la misma idea que la búsqueda de los jugadores.
En este caso es mucho más fácil ya que solo se tiene en cuenta la interacción de los dos entrenadores, por lo que en este
caso se puede hacer uso de una especie de \textbf{minimax} (con el no determinismo de las transiciones presente). Para la ejecución del mismo
se evalúan todas las posibles acciones de ambos entrenadores y se simula hasta la próxima instancia de tiempo en que le corresponda
jugar, así hasta llegar a bajar una cantidad de niveles y luego utilizar la misma evaluación del campo que utilizaban los jugadores
más simplificada.   

\section{Simulación de partidos}
\subsection{Campo de juego y posiciones}
El terreno de juego se representa gráficamente con un
array de 20 filas por 11 columnas donde se intenta simular un campo de fútbol real, con límites por los lados y por 
el fondo, y con dos porterías. Una vez que introducimos a los jugadores en el campo para simular un partido, ocupan 
las posiciones predeterminadas para cada posición, que varían dependiendo de la táctica utilizada. Aquí podemos ver 
un ejemplo de las formaciones iniciales de un partido y de las posiciones que existen: 

\includegraphics*[width=0.9\textwidth]{filed.jpg}
\bigskip

\includegraphics*[width=0.9\textwidth]{report_table.jpg}
\bigskip


\subsection{Atributos de los jugadores}
Los datos de los equipos y jugadores son extraídos de un dataset del FIFA 22 de EA Sports. Un jugador tiene un nombre, 
un conjunto de posiciones, equipo al que pertenece, un dorsal y, además, doce atributos preestablecidos. A 
continuación una relación de en què acciones se usa cada uno de los atributos:

\includegraphics*[width=0.9\textwidth]{attributed_table.jpg}
\bigskip

Además de los atributos vistos en la tabla anterior, hacemos uso de la resistencia de los jugadores. cada acción que realiza un jugador tiene un costo de estamina. Existe también la acción de moverse en  el terreno, tanto con balón como sin él, donde lo único que sucede es la disminución de estamina sin tener que utilizar ninguno de los atributos de la tabla.

Los atributos preestablecidos son valores numéricos previamente asignados en el dataset, con valores posibles del 1 al 
99, pero que generalmente se encuentran entre 60 y 85, donde se evalúa de forma precisa cómo de bueno es un jugador en 
un aspecto físico o técnico a la hora de jugar un partido. Para poner un ejemplo, un atributo es la Velocidad. Si un 
jugador llamado JUGADOR1 tiene un valor de 83 de velocidad, y otro jugador llamado JUGADOR2 tiene un valor de 70 de 
velocidad, significa que el JUGADOR1 es más rápido que el JUGADOR2. Esto quiere decir que, a la hora de jugar el 
partido, es más probable que JUGADOR1 gane a JUGADOR2 en velocidad. Es importante no confundir esta última frase. 
Es más probable que JUGADOR1 gane a JUGADOR2 en velocidad, pero no significa que JUGADOR1 gane a JUGADOR2 siempre.

Para explicar cuál es la probabilidad de que gane uno u otro jugador,
explicaremos a continuación cómo funciona el algoritmo de probabilidades:

Supongamos que ocurre un pase, donde el receptor (del equipo atacante) tiene 81 en reacciones y 85 en control del 
balón y el defensa que quiere interceptar tiene 68 en intercepción y 72 en defensa. Hacemos una normalización que 
no es màs que la media de los atributos implicados del jugador y sacaremos un valor aleatorio entre ese factor y 99. 
Ese será nuestro factor de aleatoriedad.


\includegraphics*[width=0.9\textwidth]{rank.jpg}
\bigskip

Con estos datos, podemos afirmar que, si JUGADOR1 y JUGADOR2 disputasen una recepción de un pase en medio de un 
partido, JUGADOR1 tendría más posibilidades de ganarla, pero esto no implica que tenga que ganar siempre.
Obviamente, cuanta más diferencia hay entre los valores de los jugadores, más fácil es ganar el algoritmo de 
aleatoriedad para el de valor superior. En caso de empate en los factores de aleatoriedad ganará el duelo el 
jugador a la defensa.

\subsection{Acciones de los jugadores}

Como ya mencionamos anteriormente las acciones de los jugadores ocurren en una instancia de tiempo en la que cada agente decide 
una única acción para realizar. El orden en que los agentes deciden sus acciones es secuencial y se basa en la posición que estos tengan en el campo,
comenzando por el jugador que tiene la pelota. Las acciones que pueden realizar los jugadores son las siguientes:

\begin{enumerate}
      \item \textbf{Nothing}: El jugador entre sus decisiones posibles tiene la de no hacer nada, esta es la única que no resta estamina.
            
      \item \textbf{Pass}: El jugador con balón tiene la posibilidad de pasar la pelota a los compañeros que se encuentre en su rango de vision, el pase siempre llega con éxito.
            
      \item \textbf{Move}: Todo jugador tiene la posibilidad de moverse sobre el terreno, la única limitante es que no se puede mover a un lugar donde ya haya un jugador.
            
      \item \textbf{Dribble}: Junto con la acción de moverse con el balón, el jugador puede decidir si intentar regatear para que los defensores de las casillas contiguas a la casilla objetivo no le roben el balón.
            
      \item \textbf{StealBall}: Los jugadores a la defensa tienen la posibilidad de robar el balón si alguien del equipo rival recibe un pase  o se mueve con el balón hacia una casilla contigua a la suya.
            
      \item \textbf{Shoot}: Los jugadores con balón siempre tienen la oportunidad de disparar, con un probabilidad de que el balón vaya a portería en dependencia de su habilidad de tiro y distancia a esta, y en caso de que vaya a puerta hay otra probabilidad de que sea gol.
            
\end{enumerate}


\subsection{Acciones de los entrenadores}

Los entrenadores no pueden actuar en todas las instancias de tiempo al igual que los jugadores esto tratando de imitar la realidad
en la que en todo momento los entrenadores no realizan sus acciones. Las acciones que ejecuten los entrenadores solo
serán aplicadas una vez que se reorganice el juego en el campo, esto solo ocurre cuando se produce un disparo a portería.
Las posibles acciones de los entrenadores son las siguientes:

\begin{enumerate}
      \item \textbf{ManagerNothing}: El entrenador entre sus decisiones posibles tiene la de no hacer nada.
            
      \item \textbf{ChangePlayer}: El entrenador tiene la posibilidad de cambiar jugadores del terreno por otros que pertenezcan a su lista de jugadores posibles a alinear siempre que le queden cambios.
            
      \item \textbf{ChangeLineUp}: Todo entrenador tiene la posibilidad de cambiar la formación en medio de un partido, penalizando a los jugadores que queden jugando fuera de sus posiciones habituales.
            
\end{enumerate}


\section{Integración con LLM}

El componente de \textbf{NLP} que usamos en nuestro proyecto fue darle la facilidad al usuario que desea realizar la simulación del 
juego de fútbol la posibilidad de configurar dicha simulación en lenguaje natural. Para completar esta tarea usamos la api de \textbf{Gemini}
en su versión pro, la idea básica fue realizar trabajo de \textbf{prompt engineer} a la consulta realizada por el usuario y así obtener
la consulta original en un formato que se acople a nuestro sistema.

Los posibles parámetros de configuración de la simulación son los siguientes:

\begin{itemize}
      \item \textbf{Equipos implicados en la simulación}: para obtener estos parámetros optamos por filtrar primero los
            equipos por liga ya que era imposible proporcionarle al modelo todos los equipos de nuestro dataset, así que primero
            el usuario deberá especificar la liga y luego los equipos implicados en el juego. Por tanto primero se le pide al
            modelo que identifique de todas las posibles ligas la que especificó el usuario y luego se le proporcionan todos
            los equipos de dicha liga y se le pide seleccionar el equipo local y el equipo visitante en el siguiente formato:
            FC Barcelona vs CF Real Madrid.
            
      \item \textbf{Estrategia de los entrenadores para elegir la alineación}: las posibles estrategias para el entrenador en este
            caso son \textbf{random} y \textbf{simulate} las cuales están basadas en las estrategias descritas anteriormente. Por lo
            que entonces se le pide al modelo que identifique estos parámetros.
            
      \item \textbf{Estrategia de los entrenadores para elegir las acciones durante el juego}: las posibles estrategias para el entrenador en este
            caso son \textbf{random}, \textbf{simulate} y \textbf{minimax} las cuales están basadas en las estrategias descritas anteriormente. Por lo
            que entonces se le pide al modelo que identifique estos parámetros.
            
      \item \textbf{Estrategia de los jugadores para elegir las acciones durante el juego}: las posibles estrategias para los jugadores en este
            caso son \textbf{random}, \textbf{heuristic} y \textbf{minimax} las cuales están basadas en las estrategias descritas anteriormente. Por lo
            que entonces se le pide al modelo que identifique estos parámetros.
            
            
\end{itemize}

\includegraphics*[width=0.9\textwidth]{llm.png}
\bigskip

\section{Detalles de implementación}

\subsection{Mecanismo de simulación}

Como estamos haciendo uso de varios algoritmos de búsqueda para la ejecución de las acciones de los agentes durante el juego
fue necesario la creación de un mecanismo de memoria sobre las acciones que se ejecutan. Para ello se encapsuló la lógica de cada 
acción en la clase \textbf{Action} a la cual se le implementaron las funciones \textbf{execute} y \textbf{reset}. Siguiendo esta idea se definió
un mecanismo de \textbf{Dispatch} mediante le cual los agentes ejecutan sus acciones y estas se guardan en un pila (\textbf{stack}) para después poder 
ser reseteadas en el momento que así se requiera. En el caso de las acciones de los managers que no tiene un efecto inmediato se hace 
uso de una nueva pila (\textbf{lazy\_stack}) en la cual se introducen estas acciones y en el momento indicado se comprimen y se aplican
al juego de manera análoga a lo anterior este mecanismo de acciones lazy también cuenta con un mecanismo de \textbf{reset}.

Para simular el juego en concreto de hace uso de una clase \textbf{Simulator} la cual se encarga de ejecutar una instancia de tiempo
y resetear una instancia de tiempo.

Para proveer un mecanismo de simulación de los agentes se emplea la clase \textbf{SimulatorAgent} la cual posee una función para simular 
el resto del comportamiento del medio que así lo requiera el agente, una función para simular el resto de la instancia de tiempo correspondiente
así como las respectivas funciones de reset de cada una de las funciones antes mencionadas. Además se le provee al agente una función para interactuar
directamente con el \textbf{Dispatch} del juego.

\subsection{implementación de reglas y lógica difusa}

\subsection{Encapsulamiento de las estrategias de los agentes}

Para cada tipo de acción de los agentes (jugar para los jugadores, realizar acciones durante el partido y establecer alineación para los
técnicos) se crea una interfaz que permite encapsular dicho comportamiento y que sea posible permitir más de una configuración sin afectar
el resto del funcionamiento del agente.

\section{Análisis experimental}

\section{Conclusiones}

\section{Recomendaciones}

Para futuros trabajos se recomienda un estudio más profundo del problema que permita el desarrollo de mejores heurísticas de evaluación
que las planteadas en este trabajo. Por ejemplo no nos fue posible desarrollar una buena heurística para las acciones del manager y algunas
de las introducidas para escoger la alineación o escoger el mejor cambio las consideramos que no evalúan la alineación en conjunto.
Además de consideramos importante mejorar las heurísticas empleadas en la función de evaluación lo que permitirá un mejor rendimiento 
de los algoritmos de búsqueda. Otra heurística no abordada en este trabajo pudiera consistir en al planificación de acciones conjuntas y 
colaborativas para la realización de acciones en equipo.

El estudio de mejores estrategias de búsqueda para este tipo de escenarios que pueden llegar a ser colaborativos y no deterministas puede
ser otro punto importante para mejoras futuras.

Otro aspecto que queremos resaltar y no exploramos del todo es el reajuste de los pesos con que cuentan las estrategias heurísticas de los jugadores
que en futuras implementaciones se pudiera tratar de desarrollar un algoritmo que sea capaz de reajustar estos parámetros en base a la experiencia
obtenida por el agente.



\end{document}
